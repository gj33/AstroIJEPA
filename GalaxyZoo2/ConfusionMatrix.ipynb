{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DM52sjfsiqs"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torchvision pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "bNTqBoc-spfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gj33/IJEPAGalaxyZoo.git"
      ],
      "metadata": {
        "id": "kRXvlaXIk3C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "sys.path.append('/content/IJEPAGalaxyZoo')  # Add the IJepa src directory to the Python path\n",
        "\n",
        "import src.models.vision_transformer as vit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFKKllDDt4iE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "sys.path.append('/content/IJEPAGalaxyZoo/src')  # Ensure the path is correct\n",
        "\n",
        "from models.vision_transformer import vit_tiny\n"
      ],
      "metadata": {
        "id": "Dnm8L0-T375j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GalaxyClassifier(nn.Module):\n",
        "    def __init__(self, backbone, embed_dim=192, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        patch_embeddings = self.backbone(x)     # [B, 256, 192]\n",
        "        pooled = patch_embeddings.mean(dim=1)   # [B, 192]\n",
        "        logits = self.classifier(pooled)        # [B, 8]\n",
        "        return logits"
      ],
      "metadata": {
        "id": "JLiQqr7XFCyD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_vit_model = vit_tiny(\n",
        "    img_size=[224],\n",
        "    patch_size=14,\n",
        "    drop_rate=0.0,\n",
        "    attn_drop_rate=0.0,\n",
        "    drop_path_rate=0.0,\n",
        "    use_checkpoint=False,\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GalaxyClassifier(backbone=base_vit_model, embed_dim=192, num_classes=8).to(device)\n",
        "\n",
        "\n",
        "# Load the checkpoint from after fine-tuning\n",
        "checkpoint_path = '/content/drive/MyDrive/GalaxyZoo/checkpoints2/models_epoch_10.pth'\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "state_dict = checkpoint\n",
        "\n",
        "state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "print(\"Checkpoint loaded successfully into the GalaxyClassifier model.\")"
      ],
      "metadata": {
        "id": "AnbUeGEy9UkD",
        "outputId": "eab931ac-6cac-40eb-f6f5-c0d1390b55db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint keys: odict_keys(['backbone.pos_embed', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.norm1.weight', 'backbone.blocks.0.norm1.bias', 'backbone.blocks.0.attn.qkv.weight', 'backbone.blocks.0.attn.qkv.bias', 'backbone.blocks.0.attn.proj.weight', 'backbone.blocks.0.attn.proj.bias', 'backbone.blocks.0.norm2.weight', 'backbone.blocks.0.norm2.bias', 'backbone.blocks.0.mlp.fc1.weight', 'backbone.blocks.0.mlp.fc1.bias', 'backbone.blocks.0.mlp.fc2.weight', 'backbone.blocks.0.mlp.fc2.bias', 'backbone.blocks.1.norm1.weight', 'backbone.blocks.1.norm1.bias', 'backbone.blocks.1.attn.qkv.weight', 'backbone.blocks.1.attn.qkv.bias', 'backbone.blocks.1.attn.proj.weight', 'backbone.blocks.1.attn.proj.bias', 'backbone.blocks.1.norm2.weight', 'backbone.blocks.1.norm2.bias', 'backbone.blocks.1.mlp.fc1.weight', 'backbone.blocks.1.mlp.fc1.bias', 'backbone.blocks.1.mlp.fc2.weight', 'backbone.blocks.1.mlp.fc2.bias', 'backbone.blocks.2.norm1.weight', 'backbone.blocks.2.norm1.bias', 'backbone.blocks.2.attn.qkv.weight', 'backbone.blocks.2.attn.qkv.bias', 'backbone.blocks.2.attn.proj.weight', 'backbone.blocks.2.attn.proj.bias', 'backbone.blocks.2.norm2.weight', 'backbone.blocks.2.norm2.bias', 'backbone.blocks.2.mlp.fc1.weight', 'backbone.blocks.2.mlp.fc1.bias', 'backbone.blocks.2.mlp.fc2.weight', 'backbone.blocks.2.mlp.fc2.bias', 'backbone.blocks.3.norm1.weight', 'backbone.blocks.3.norm1.bias', 'backbone.blocks.3.attn.qkv.weight', 'backbone.blocks.3.attn.qkv.bias', 'backbone.blocks.3.attn.proj.weight', 'backbone.blocks.3.attn.proj.bias', 'backbone.blocks.3.norm2.weight', 'backbone.blocks.3.norm2.bias', 'backbone.blocks.3.mlp.fc1.weight', 'backbone.blocks.3.mlp.fc1.bias', 'backbone.blocks.3.mlp.fc2.weight', 'backbone.blocks.3.mlp.fc2.bias', 'backbone.blocks.4.norm1.weight', 'backbone.blocks.4.norm1.bias', 'backbone.blocks.4.attn.qkv.weight', 'backbone.blocks.4.attn.qkv.bias', 'backbone.blocks.4.attn.proj.weight', 'backbone.blocks.4.attn.proj.bias', 'backbone.blocks.4.norm2.weight', 'backbone.blocks.4.norm2.bias', 'backbone.blocks.4.mlp.fc1.weight', 'backbone.blocks.4.mlp.fc1.bias', 'backbone.blocks.4.mlp.fc2.weight', 'backbone.blocks.4.mlp.fc2.bias', 'backbone.blocks.5.norm1.weight', 'backbone.blocks.5.norm1.bias', 'backbone.blocks.5.attn.qkv.weight', 'backbone.blocks.5.attn.qkv.bias', 'backbone.blocks.5.attn.proj.weight', 'backbone.blocks.5.attn.proj.bias', 'backbone.blocks.5.norm2.weight', 'backbone.blocks.5.norm2.bias', 'backbone.blocks.5.mlp.fc1.weight', 'backbone.blocks.5.mlp.fc1.bias', 'backbone.blocks.5.mlp.fc2.weight', 'backbone.blocks.5.mlp.fc2.bias', 'backbone.blocks.6.norm1.weight', 'backbone.blocks.6.norm1.bias', 'backbone.blocks.6.attn.qkv.weight', 'backbone.blocks.6.attn.qkv.bias', 'backbone.blocks.6.attn.proj.weight', 'backbone.blocks.6.attn.proj.bias', 'backbone.blocks.6.norm2.weight', 'backbone.blocks.6.norm2.bias', 'backbone.blocks.6.mlp.fc1.weight', 'backbone.blocks.6.mlp.fc1.bias', 'backbone.blocks.6.mlp.fc2.weight', 'backbone.blocks.6.mlp.fc2.bias', 'backbone.blocks.7.norm1.weight', 'backbone.blocks.7.norm1.bias', 'backbone.blocks.7.attn.qkv.weight', 'backbone.blocks.7.attn.qkv.bias', 'backbone.blocks.7.attn.proj.weight', 'backbone.blocks.7.attn.proj.bias', 'backbone.blocks.7.norm2.weight', 'backbone.blocks.7.norm2.bias', 'backbone.blocks.7.mlp.fc1.weight', 'backbone.blocks.7.mlp.fc1.bias', 'backbone.blocks.7.mlp.fc2.weight', 'backbone.blocks.7.mlp.fc2.bias', 'backbone.blocks.8.norm1.weight', 'backbone.blocks.8.norm1.bias', 'backbone.blocks.8.attn.qkv.weight', 'backbone.blocks.8.attn.qkv.bias', 'backbone.blocks.8.attn.proj.weight', 'backbone.blocks.8.attn.proj.bias', 'backbone.blocks.8.norm2.weight', 'backbone.blocks.8.norm2.bias', 'backbone.blocks.8.mlp.fc1.weight', 'backbone.blocks.8.mlp.fc1.bias', 'backbone.blocks.8.mlp.fc2.weight', 'backbone.blocks.8.mlp.fc2.bias', 'backbone.blocks.9.norm1.weight', 'backbone.blocks.9.norm1.bias', 'backbone.blocks.9.attn.qkv.weight', 'backbone.blocks.9.attn.qkv.bias', 'backbone.blocks.9.attn.proj.weight', 'backbone.blocks.9.attn.proj.bias', 'backbone.blocks.9.norm2.weight', 'backbone.blocks.9.norm2.bias', 'backbone.blocks.9.mlp.fc1.weight', 'backbone.blocks.9.mlp.fc1.bias', 'backbone.blocks.9.mlp.fc2.weight', 'backbone.blocks.9.mlp.fc2.bias', 'backbone.blocks.10.norm1.weight', 'backbone.blocks.10.norm1.bias', 'backbone.blocks.10.attn.qkv.weight', 'backbone.blocks.10.attn.qkv.bias', 'backbone.blocks.10.attn.proj.weight', 'backbone.blocks.10.attn.proj.bias', 'backbone.blocks.10.norm2.weight', 'backbone.blocks.10.norm2.bias', 'backbone.blocks.10.mlp.fc1.weight', 'backbone.blocks.10.mlp.fc1.bias', 'backbone.blocks.10.mlp.fc2.weight', 'backbone.blocks.10.mlp.fc2.bias', 'backbone.blocks.11.norm1.weight', 'backbone.blocks.11.norm1.bias', 'backbone.blocks.11.attn.qkv.weight', 'backbone.blocks.11.attn.qkv.bias', 'backbone.blocks.11.attn.proj.weight', 'backbone.blocks.11.attn.proj.bias', 'backbone.blocks.11.norm2.weight', 'backbone.blocks.11.norm2.bias', 'backbone.blocks.11.mlp.fc1.weight', 'backbone.blocks.11.mlp.fc1.bias', 'backbone.blocks.11.mlp.fc2.weight', 'backbone.blocks.11.mlp.fc2.bias', 'backbone.norm.weight', 'backbone.norm.bias', 'backbone.head.weight', 'backbone.head.bias', 'classifier.weight', 'classifier.bias'])\n",
            "Checkpoint loaded successfully into the GalaxyClassifier model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GalaxyClassifier(backbone=model, embed_dim=192, num_classes=8).to(device)"
      ],
      "metadata": {
        "id": "fBXeO8HxFYMl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in TinyImageNet\n",
        "num_classes = 8\n",
        "\n",
        "# Replace the head with a new classification head\n",
        "model.head = nn.Linear(model.embed_dim, num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "4P_R9wEGuKSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
        "        std=[0.229, 0.224, 0.225],   # ImageNet std\n",
        "    ),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "1BWzNesjuSDr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from logging import getLogger\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "logger = getLogger()\n",
        "\n",
        "dir_cat = \"/content/drive/MyDrive/GalaxyZoo/\"\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "df = pd.read_csv(dir_cat+'gz2_valid.csv')\n",
        "class GalaxyZooDataset(Dataset):\n",
        "    '''Galaxy Zoo 2 image dataset\n",
        "        Args:\n",
        "            dataframe : pd.dataframe, outputs from the data_split function\n",
        "                e.g. df_train / df_valid / df_test\n",
        "            dir_image : str, path where galaxy images are located\n",
        "            label_tag : str, class label system to be used for training\n",
        "                e.g. label_tag = 'label1' / 'label2' / 'label3' / 'label4'\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dataframe, dir_image, label_tag='label1', transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        self.dir_image = dir_image\n",
        "        self.label_tag = label_tag\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        galaxyID = self.df.iloc[[index]].galaxyID.values[0]\n",
        "        file_img = os.path.join(self.dir_image, str(galaxyID) + '.jpg')\n",
        "        image = Image.open(file_img)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.df.iloc[[index]][self.label_tag].values[0]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "collator=None\n",
        "pin_mem=True\n",
        "num_workers=8\n",
        "world_size=1\n",
        "rank=0\n",
        "root_path=None\n",
        "image_folder=None\n",
        "training=True\n",
        "copy_data=False\n",
        "drop_last=True\n",
        "subset_file=None\n",
        "\n",
        "if transform is None:\n",
        "\n",
        "    transform = transforms.ToTensor()\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "dataset_valid = GalaxyZooDataset(df, dir_image, label_tag='label1', transform=transform)\n",
        "logger.info('ImageNet dataset created')\n",
        "dist_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    dataset=dataset_valid,\n",
        "    num_replicas=world_size,\n",
        "    rank=rank)\n",
        "valid_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset_valid,\n",
        "    collate_fn=collator,\n",
        "    sampler=dist_sampler,\n",
        "    batch_size=32,\n",
        "    drop_last=drop_last,\n",
        "    pin_memory=pin_mem,\n",
        "    num_workers=num_workers,\n",
        "    persistent_workers=False)"
      ],
      "metadata": {
        "id": "5zJDH9-eQgUg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/ijepa/data/GalaxyZoo"
      ],
      "metadata": {
        "id": "HIfCyG8Zty6f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/GalaxyZoo/archive.zip -d /content/ijepa/data/GalaxyZoo/"
      ],
      "metadata": {
        "id": "nckzkpI5t1Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "model.eval()\n",
        "correct_top1 = 0\n",
        "correct_top3 = 0\n",
        "total = 0\n",
        "\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "     for images, labels in valid_data_loader:\n",
        "         images = images.to(device, non_blocking=True)\n",
        "         labels = labels.to(device, non_blocking=True)\n",
        "         outputs = model(images)\n",
        "         _, preds = outputs.topk(3, dim=1, largest=True, sorted=True)\n",
        "\n",
        "         total += labels.size(0)\n",
        "         correct_top1 += (preds[:, 0] == labels).sum().item()\n",
        "         correct_top3 += (preds == labels.view(-1, 1)).sum().item()\n",
        "\n",
        "\n",
        "         all_preds.extend(preds[:, 0].cpu().numpy())\n",
        "         all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "top1_acc = 100 * correct_top1 / total\n",
        "top3_acc = 100 * correct_top3 / total\n",
        "print(f'Validation Top-1 Accuracy: {top1_acc:.2f}%, Top-3 Accuracy: {top3_acc:.2f}%')\n",
        "\n",
        "    # Confusion Matrix\n",
        "num_classes = 8\n",
        "conf_mat = confusion_matrix(all_targets, all_preds, labels=list(range(num_classes)))\n",
        "conf_mat_normalized = conf_mat.astype(float) / conf_mat.sum(axis=1, keepdims=True)\n",
        "\n",
        "conf_df = pd.DataFrame(conf_mat_normalized,\n",
        "                        index=[f\"True {i}\" for i in range(num_classes)],\n",
        "                        columns=[f\"Pred {i}\" for i in range(num_classes)])\n",
        "\n",
        "print(\"\\nNormalized Confusion Matrix (% per true class):\")\n",
        "print(conf_df.to_string(float_format=\"%.2f\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBM7ymm7xs0I",
        "outputId": "c83feb63-fae6-46fb-db3f-e47d99b0e439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Top-1 Accuracy: 70.03%, Top-3 Accuracy: 94.68%\n",
            "\n",
            "Normalized Confusion Matrix (% per true class):\n",
            "        Pred 0  Pred 1  Pred 2  Pred 3  Pred 4  Pred 5  Pred 6  Pred 7\n",
            "True 0    0.80    0.13    0.00    0.00    0.01    0.04    0.01    0.00\n",
            "True 1    0.15    0.71    0.02    0.01    0.02    0.08    0.01    0.00\n",
            "True 2    0.01    0.14    0.41    0.33    0.01    0.09    0.01    0.00\n",
            "True 3    0.02    0.04    0.03    0.84    0.01    0.05    0.00    0.00\n",
            "True 4    0.02    0.06    0.00    0.02    0.71    0.17    0.01    0.00\n",
            "True 5    0.06    0.10    0.01    0.02    0.12    0.66    0.02    0.00\n",
            "True 6    0.08    0.12    0.02    0.06    0.12    0.24    0.34    0.03\n",
            "True 7    0.08    0.14    0.00    0.06    0.18    0.16    0.10    0.28\n"
          ]
        }
      ]
    }
  ]
}