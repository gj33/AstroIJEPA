{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DM52sjfsiqs"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torchvision pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNTqBoc-spfM",
        "outputId": "46dc670b-ef6d-45eb-ec3f-ff8a238e0036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gj33/IJEPAGalaxyZoo.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRXvlaXIk3C4",
        "outputId": "8feba2a0-c9e7-4e71-c7fa-18ab93dbc326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IJEPAGalaxyZoo'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 53 (delta 15), reused 27 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 63.17 KiB | 10.53 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "sys.path.append('/content/IJEPAGalaxyZoo')  # Add the IJepa src directory to the Python path\n",
        "\n",
        "import src.models.vision_transformer as vit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFKKllDDt4iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "sys.path.append('/content/IJEPAGalaxyZoo/src')  # Ensure the path is correct\n",
        "\n",
        "from models.vision_transformer import vit_tiny\n"
      ],
      "metadata": {
        "id": "Dnm8L0-T375j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GalaxyClassifier(nn.Module):\n",
        "    def __init__(self, backbone, embed_dim=192, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        patch_embeddings = self.backbone(x)     # [B, 256, 192]\n",
        "        pooled = patch_embeddings.mean(dim=1)   # [B, 192]\n",
        "        logits = self.classifier(pooled)        # [B, 8]\n",
        "        return logits"
      ],
      "metadata": {
        "id": "JLiQqr7XFCyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_vit_model = vit_tiny(\n",
        "    img_size=[224],\n",
        "    patch_size=14,\n",
        "    drop_rate=0.0,\n",
        "    attn_drop_rate=0.0,\n",
        "    drop_path_rate=0.0,\n",
        "    use_checkpoint=False,\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GalaxyClassifier(backbone=base_vit_model, embed_dim=192, num_classes=8).to(device)\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/ijepa_logs/GalaxyZooOutput1/jepa-ep30.pth.tar'\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "\n",
        "print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "\n",
        "state_dict = checkpoint\n",
        "\n",
        "\n",
        "state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "print(\"Checkpoint loaded successfully into the GalaxyClassifier model.\")"
      ],
      "metadata": {
        "id": "AnbUeGEy9UkD",
        "outputId": "ab3fe494-8f9c-47e1-d081-2af665c65b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint keys: dict_keys(['encoder', 'predictor', 'target_encoder', 'opt', 'scaler', 'epoch', 'loss', 'batch_size', 'world_size', 'lr'])\n",
            "Checkpoint loaded successfully into the GalaxyClassifier model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in TinyImageNet\n",
        "num_classes = 8\n",
        "\n",
        "# Replace the head with a new classification head\n",
        "model.classifier = nn.Linear(model.backbone.embed_dim, num_classes)"
      ],
      "metadata": {
        "id": "4P_R9wEGuKSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
        "        std=[0.229, 0.224, 0.225],   # ImageNet std\n",
        "    ),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "1BWzNesjuSDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from logging import getLogger\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "logger = getLogger()\n",
        "\n",
        "dir_cat = \"/content/drive/MyDrive/GalaxyZoo/\"\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "df = pd.read_csv(dir_cat+'gz2_train.csv')\n",
        "df2 = pd.read_csv(dir_cat+'gz2_valid.csv')\n",
        "class GalaxyZooDataset(Dataset):\n",
        "    '''Galaxy Zoo 2 image dataset\n",
        "        Args:\n",
        "            dataframe : pd.dataframe, outputs from the data_split function\n",
        "                e.g. df_train / df_valid / df_test\n",
        "            dir_image : str, path where galaxy images are located\n",
        "            label_tag : str, class label system to be used for training\n",
        "                e.g. label_tag = 'label1' / 'label2' / 'label3' / 'label4'\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dataframe, dir_image, label_tag='label1', transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        self.dir_image = dir_image\n",
        "        self.label_tag = label_tag\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        galaxyID = self.df.iloc[[index]].galaxyID.values[0]\n",
        "        file_img = os.path.join(self.dir_image, str(galaxyID) + '.jpg')\n",
        "        image = Image.open(file_img)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.df.iloc[[index]][self.label_tag].values[0]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "collator=None\n",
        "pin_mem=True\n",
        "num_workers=8\n",
        "world_size=1\n",
        "rank=0\n",
        "root_path=None\n",
        "image_folder=None\n",
        "training=True\n",
        "copy_data=False\n",
        "drop_last=True\n",
        "subset_file=None\n",
        "\n",
        "if transform is None:\n",
        "    # If no transform provided, at least convert images to Tensors\n",
        "    transform = transforms.ToTensor()\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "dataset = GalaxyZooDataset(df, dir_image, label_tag='label1', transform=transform)\n",
        "logger.info('ImageNet dataset created')\n",
        "dist_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    dataset=dataset,\n",
        "    num_replicas=world_size,\n",
        "    rank=rank)\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    collate_fn=collator,\n",
        "    sampler=dist_sampler,\n",
        "    batch_size=32,\n",
        "    drop_last=drop_last,\n",
        "    pin_memory=pin_mem,\n",
        "    num_workers=num_workers,\n",
        "    persistent_workers=False)"
      ],
      "metadata": {
        "id": "JVcUgR0Kmx5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from logging import getLogger\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "logger = getLogger()\n",
        "\n",
        "dir_cat = \"/content/drive/MyDrive/GalaxyZoo/\"\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "df = pd.read_csv(dir_cat+'gz2_valid.csv')\n",
        "class GalaxyZooDataset(Dataset):\n",
        "    '''Galaxy Zoo 2 image dataset\n",
        "        Args:\n",
        "            dataframe : pd.dataframe, outputs from the data_split function\n",
        "                e.g. df_train / df_valid / df_test\n",
        "            dir_image : str, path where galaxy images are located\n",
        "            label_tag : str, class label system to be used for training\n",
        "                e.g. label_tag = 'label1' / 'label2' / 'label3' / 'label4'\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dataframe, dir_image, label_tag='label1', transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        self.dir_image = dir_image\n",
        "        self.label_tag = label_tag\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        galaxyID = self.df.iloc[[index]].galaxyID.values[0]\n",
        "        file_img = os.path.join(self.dir_image, str(galaxyID) + '.jpg')\n",
        "        image = Image.open(file_img)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.df.iloc[[index]][self.label_tag].values[0]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "collator=None\n",
        "pin_mem=True\n",
        "num_workers=8\n",
        "world_size=1\n",
        "rank=0\n",
        "root_path=None\n",
        "image_folder=None\n",
        "training=True\n",
        "copy_data=False\n",
        "drop_last=True\n",
        "subset_file=None\n",
        "\n",
        "if transform is None:\n",
        "    # If no transform provided, at least convert images to Tensors\n",
        "    transform = transforms.ToTensor()\n",
        "dir_image = '/content/ijepa/data/GalaxyZoo/images_gz2/images'\n",
        "dataset_valid = GalaxyZooDataset(df, dir_image, label_tag='label1', transform=transform)\n",
        "logger.info('ImageNet dataset created')\n",
        "dist_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    dataset=dataset_valid,\n",
        "    num_replicas=world_size,\n",
        "    rank=rank)\n",
        "valid_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset_valid,\n",
        "    collate_fn=collator,\n",
        "    sampler=dist_sampler,\n",
        "    batch_size=32,\n",
        "    drop_last=drop_last,\n",
        "    pin_memory=pin_mem,\n",
        "    num_workers=num_workers,\n",
        "    persistent_workers=False)"
      ],
      "metadata": {
        "id": "5zJDH9-eQgUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all layers\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Use a smaller learning rate for the encoder parameters\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)"
      ],
      "metadata": {
        "id": "U28OjFBisFLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/ijepa/data/GalaxyZoo"
      ],
      "metadata": {
        "id": "HIfCyG8Zty6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/GalaxyZoo/archive.zip -d /content/ijepa/data/GalaxyZoo/"
      ],
      "metadata": {
        "id": "nckzkpI5t1Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#create directory to store checkpoints\n",
        "checkpoint_dir = '/content/drive/MyDrive/GalaxyZoo/galaxyzoocheckpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "D9ab8WACUdzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_data_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        model.to(device) # Ensure model is on the correct device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model.eval()\n",
        "    correct_top1 = 0\n",
        "    correct_top3 = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_data_loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            model.to(device) # Ensure model is on the correct device\n",
        "            outputs = model(images)\n",
        "            _, preds = outputs.topk(3, dim=1, largest=True, sorted=True)\n",
        "            total += labels.size(0)\n",
        "            correct_top1 += (preds[:, 0] == labels).sum().item()\n",
        "            correct_top3 += (preds == labels.view(-1, 1)).sum().item()\n",
        "    top1_acc = 100 * correct_top1 / total\n",
        "    top3_acc = 100 * correct_top3 / total\n",
        "    print(f'Validation Top-1 Accuracy: {top1_acc:.2f}%, Top-3 Accuracy: {top3_acc:.2f}%')\n",
        "    model.eval()\n",
        "    correct_top1 = 0\n",
        "    correct_top3 = 0\n",
        "    total = 0\n",
        "\n",
        "    # Evaluate on training set too to test for overfitting\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_data_loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            model.to(device) # Ensure model is on the correct device\n",
        "            outputs = model(images)\n",
        "            _, preds = outputs.topk(3, dim=1, largest=True, sorted=True)\n",
        "            total += labels.size(0)\n",
        "            correct_top1 += (preds[:, 0] == labels).sum().item()\n",
        "            correct_top3 += (preds == labels.view(-1, 1)).sum().item()\n",
        "    top1_acc = 100 * correct_top1 / total\n",
        "    top3_acc = 100 * correct_top3 / total\n",
        "    print(f'Training Top-1 Accuracy: {top1_acc:.2f}%, Top-3 Accuracy: {top3_acc:.2f}%')\n",
        "    torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'models_epoch_{epoch+1}.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyt6dZNTtKhn",
        "outputId": "6a10ac86-283e-44e5-c89d-1f8270e747a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.4429\n",
            "Validation Top-1 Accuracy: 52.21%, Top-3 Accuracy: 86.59%\n",
            "Training Top-1 Accuracy: 52.78%, Top-3 Accuracy: 86.76%\n",
            "Epoch [2/10], Loss: 1.1501\n",
            "Validation Top-1 Accuracy: 58.64%, Top-3 Accuracy: 89.87%\n",
            "Training Top-1 Accuracy: 59.32%, Top-3 Accuracy: 89.89%\n",
            "Epoch [3/10], Loss: 1.0691\n",
            "Validation Top-1 Accuracy: 60.81%, Top-3 Accuracy: 90.85%\n",
            "Training Top-1 Accuracy: 60.84%, Top-3 Accuracy: 90.75%\n",
            "Epoch [4/10], Loss: 1.0346\n",
            "Validation Top-1 Accuracy: 60.69%, Top-3 Accuracy: 90.65%\n",
            "Training Top-1 Accuracy: 60.66%, Top-3 Accuracy: 90.97%\n",
            "Epoch [5/10], Loss: 1.0078\n",
            "Validation Top-1 Accuracy: 63.37%, Top-3 Accuracy: 91.90%\n",
            "Training Top-1 Accuracy: 63.26%, Top-3 Accuracy: 91.89%\n",
            "Epoch [6/10], Loss: 0.9828\n",
            "Validation Top-1 Accuracy: 63.44%, Top-3 Accuracy: 91.93%\n",
            "Training Top-1 Accuracy: 63.31%, Top-3 Accuracy: 92.01%\n",
            "Epoch [7/10], Loss: 0.9660\n",
            "Validation Top-1 Accuracy: 64.71%, Top-3 Accuracy: 92.44%\n",
            "Training Top-1 Accuracy: 65.13%, Top-3 Accuracy: 92.71%\n",
            "Epoch [8/10], Loss: 0.9487\n",
            "Validation Top-1 Accuracy: 65.42%, Top-3 Accuracy: 93.06%\n"
          ]
        }
      ]
    }
  ]
}